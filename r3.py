# -*- coding: utf-8 -*-
"""
DAEWC paper-style experiment (NO CLI args; config is inside this file)

Cross-domain fake news detection:
  Source: Political (ISOT politics subset)  ->  Target: Medical (COVID dataset)

Key fixes vs your previous script:
1) Identity initialization for NEW-domain adapters & gates:
   - adapter up-proj kernel/bias = zeros => adapter output starts at 0
   - gate uses 2*sigmoid(preact) and last gate layer = zeros => gate starts at 1 (identity)
   This prevents random adapters/gates from destroying the pretrained backbone in few-shot.

2) One source pretrain ONLY (plain backbone), then copy backbone weights into DAEWC model.
   This matches the paper narrative Stage A -> Stage B and avoids "pretraining a different architecture".

3) Backbone-only EWC on "protected" backbone vars (kernels/embeddings),
   while allowing backbone biases to update as "calibration params" (no EWC on bias).

4) Few-shot needs enough gradient steps:
   - smaller target batch size
   - longer epochs with early stopping
   - 2-stage adaptation: Stage1 adapters/gates/head; Stage2 small backbone update under EWC

Outputs:
- raw CSV per seed+shot+method
- summary CSV: mean + 95% CI over seeds

Author: (generated by ChatGPT, revised per your DAEWC paper)
"""

import os
import random
import time
import gc
import re
import hashlib
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import tensorflow as tf

from tensorflow.keras import Model
from tensorflow.keras import layers as L
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


# =========================================================
# 0. GPU + Reproducibility
# =========================================================

def setup_gpu():
    gpus = tf.config.list_physical_devices("GPU")
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except Exception as e:
            print("GPU memory growth set failed:", e)

def reset_seeds(seed: int):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

def clear_tf():
    tf.keras.backend.clear_session()
    gc.collect()

setup_gpu()


# =========================================================
# 1. Config (EDIT HERE)
# =========================================================

# ---------- data paths ----------
PATH_FAKE = "./news/Fake.csv"
PATH_REAL = "./news/True.csv"
PATH_COVID_FAKE = "./covid/fakeNews.csv"
PATH_COVID_REAL = "./covid/trueNews.csv"

# ---------- experiment seeds ----------
SEEDS = [42, 43, 44, 45, 46]
DATA_SPLIT_SEED = 123  # fixed splits
KSHOT_SAMPLE_SEED = 123  # fixed few-shot subset per shot (for fair seed variance = init/opt only)

# Few-shot setting: k-shot PER CLASS (binary => 2k total)
SHOTS_PER_CLASS_LIST = [10, 20, 80, 160]

# ---------- split ratios ----------
TEST_SIZE = 0.20
DEV_SIZE = 0.10

# ---------- preprocessing ----------
MIN_CHAR_LEN = 40
LOWERCASE = True
REMOVE_URLS = True
REMOVE_USERNAMES = True
NORMALIZE_SPACES = True

# Tokenizer / padding
MAX_NUM_WORDS = 5000
MAXLEN = 1000
TOKENIZER_MODE = "source"  # "source" (paper-strict) OR "union"
DEDUP_GROUP_SPLIT = True   # avoid exact-duplicate leakage across train/dev/test
KSHOT_UNIQUE_TEXT = True   # sample few-shot from UNIQUE normalized-hash texts
CROSS_DOMAIN_DEDUP = True  # remove exact normalized duplicates between source & target

# ---------- model (CNN backbone) ----------
EMBED_DIM = 100
CONV_FILTERS = 128
KERNEL_SIZE = 5
DENSE_UNITS = 128
DROPOUT = 0.5

# Adapter / Gate
ADAPTER_R = 16
GATE_HIDDEN = 64
NUM_DOMAINS = 2  # 0=political, 1=medical

# ---------- training ----------
EPOCHS_SOURCE = 6

# Few-shot adaptation: make sure we have enough optimization steps
EPOCHS_TARGET_STAGE1 = 30   # adapters/gates/head only
EPOCHS_TARGET_STAGE2 = 30   # + small backbone update under EWC

BATCH_SIZE_SOURCE = 64
BATCH_SIZE_TARGET = 16  # IMPORTANT: few-shot needs smaller batch

LR_SOURCE = 1e-3
LR_TARGET = 8e-4  # slightly smaller is often more stable for few-shot

EARLY_STOP_PATIENCE = 5  # early stopping on target dev

# Stage2 backbone gradient scaling (<1 => gentle backbone movement)
BACKBONE_LR_MULT = 0.3

# ---------- EWC ----------
USE_EWC = True

# Strong default (you can tune):
EWC_LAMBDA = 10.0

# Optional proximity term (L2 to source solution) on protected backbone vars
PROX_ALPHA = 1e-4

# Fisher estimation
FISHER_SAMPLES = 2000
FISHER_BATCH_SIZE = 64
FISHER_LABEL_SMOOTH = 0.0
FISHER_TRAINING_TRUE = False

# EWC protects only these backbone vars:
# - embeddings and kernels
# - NOT biases (bias treated as calibration)
EWC_PROTECT_BIAS = False

# ---------- optional: auto-tune DAEWC lambda on DEV (recommended if you want DAEWC strongest) ----------
AUTO_TUNE_DAEWC_LAMBDA = True
DAEWC_LAMBDA_GRID = [1.0, 5.0, 10.0, 20.0, 40.0]
# score = target_dev_f1 - beta * max(0, (src_dev_drop - tol))
TUNE_BETA_FORGET = 2.0
TUNE_FORGET_TOL = 0.005  # allow tiny drop on source dev

# ---------- evaluation ----------
CALIBRATE_THR_ON_DEV = True
THR_GRID_SIZE = 201

# ---------- baselines toggles ----------
INCLUDE_SCRATCH = True
INCLUDE_REPLAY_UPPER = True
INCLUDE_PLAIN_EWC = True
INCLUDE_ADAPTER_ONLY = True
INCLUDE_DAEWC = True

# Outputs
OUT_RAW_CSV = "results_daeewc_paperstyle_v3_raw.csv"
OUT_SUMMARY_CSV = "results_daeewc_paperstyle_v3_summary.csv"


# =========================================================
# 2. Utilities
# =========================================================

_url_pat = re.compile(r"https?://\S+|www\.\S+")
_user_pat = re.compile(r"@\w+")
_space_pat = re.compile(r"\s+")

def basic_clean(s: str) -> str:
    s = "" if s is None else str(s)
    s = s.strip()
    if LOWERCASE:
        s = s.lower()
    if REMOVE_URLS:
        s = _url_pat.sub(" ", s)
    if REMOVE_USERNAMES:
        s = _user_pat.sub(" ", s)
    if NORMALIZE_SPACES:
        s = _space_pat.sub(" ", s).strip()
    return s

def build_tokenizer(texts: List[str], num_words: int) -> Tuple[Tokenizer, int]:
    tok = Tokenizer(num_words=num_words, oov_token="<OOV>")
    tok.fit_on_texts(texts)
    vocab_size = min(num_words, len(tok.word_index) + 1)
    return tok, vocab_size

def vectorize(tok: Tokenizer, texts: List[str], maxlen: int) -> np.ndarray:
    seqs = tok.texts_to_sequences(texts)
    return pad_sequences(seqs, maxlen=maxlen)

def domain_ids(n: int, domain: int) -> np.ndarray:
    return np.full((n,), domain, dtype=np.int32)

def count_trainable_params(model: tf.keras.Model) -> int:
    return int(np.sum([np.prod(v.shape) for v in model.trainable_variables]))

def bce_value(y_true: np.ndarray, y_prob: np.ndarray) -> float:
    y_true = np.asarray(y_true).astype(np.float32).reshape(-1, 1)
    y_prob = np.asarray(y_prob).astype(np.float32).reshape(-1, 1)
    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)
    return float(loss_fn(y_true, y_prob).numpy())

def pick_text_col(df: pd.DataFrame) -> str:
    for c in ["Text", "text", "content", "Content", "news", "News", "claim", "Claim", "statement", "Statement"]:
        if c in df.columns:
            return c
    raise ValueError(f"Cannot find text column. Columns={list(df.columns)}")


# ---------- Dedup / leakage controls ----------
def _normalize_for_hash(text: str) -> str:
    t = str(text).lower()
    t = _url_pat.sub(" ", t)
    t = _user_pat.sub(" ", t)
    t = re.sub(r"[^a-z0-9\s]+", " ", t)
    t = _space_pat.sub(" ", t).strip()
    return t

def _text_hash(text: str) -> str:
    return hashlib.md5(_normalize_for_hash(text).encode("utf-8")).hexdigest()

def _group_keys(texts: List[str]) -> List[str]:
    return [_text_hash(t) for t in texts]


def split_train_dev_test(
    texts: List[str],
    labels: np.ndarray,
    seed: int,
    test_size: float = TEST_SIZE,
    dev_size: float = DEV_SIZE
):
    """
    Split into train/dev/test.
    If DEDUP_GROUP_SPLIT=True, do grouped split by normalized text hash
    to prevent duplicate leakage across splits.
    """
    labels = np.asarray(labels).astype(int)
    texts = list(texts)

    if not DEDUP_GROUP_SPLIT:
        X_train, X_temp, y_train, y_temp = train_test_split(
            texts, labels, test_size=(test_size + dev_size),
            random_state=seed, stratify=labels
        )
        X_dev, X_test, y_dev, y_test = train_test_split(
            X_temp, y_temp, test_size=(test_size / (test_size + dev_size)),
            random_state=seed, stratify=y_temp
        )
        return X_train, X_dev, X_test, y_train, y_dev, y_test

    keys = _group_keys(texts)
    key2idx = {}
    for i, k in enumerate(keys):
        key2idx.setdefault(k, []).append(i)

    group_keys = []
    group_labels = []
    for k, idxs in key2idx.items():
        labs = labels[idxs]
        vals, cnts = np.unique(labs, return_counts=True)
        lab = int(vals[int(np.argmax(cnts))])
        group_keys.append(k)
        group_labels.append(lab)

    group_keys = np.array(group_keys)
    group_labels = np.array(group_labels)

    g_train, g_temp, y_g_train, y_g_temp = train_test_split(
        group_keys, group_labels, test_size=(test_size + dev_size),
        random_state=seed, stratify=group_labels
    )
    g_dev, g_test, y_g_dev, y_g_test = train_test_split(
        g_temp, y_g_temp, test_size=(test_size / (test_size + dev_size)),
        random_state=seed, stratify=y_g_temp
    )

    def expand(g_keys: np.ndarray):
        idxs = []
        for k in g_keys:
            idxs.extend(key2idx[str(k)])
        return idxs

    train_idx = expand(g_train)
    dev_idx = expand(g_dev)
    test_idx = expand(g_test)

    rng = np.random.RandomState(seed)
    rng.shuffle(train_idx)
    rng.shuffle(dev_idx)
    rng.shuffle(test_idx)

    X_train = [texts[i] for i in train_idx]
    X_dev = [texts[i] for i in dev_idx]
    X_test = [texts[i] for i in test_idx]
    y_train = labels[train_idx]
    y_dev = labels[dev_idx]
    y_test = labels[test_idx]
    return X_train, X_dev, X_test, y_train, y_dev, y_test


def sample_k_shot_per_class(
    X_texts: List[str],
    y: np.ndarray,
    k: int,
    seed: int
) -> Tuple[List[str], np.ndarray]:
    """
    Balanced k-shot per class for binary labels {0,1}.
    If KSHOT_UNIQUE_TEXT=True, sample from UNIQUE normalized text hashes.
    """
    y = np.asarray(y).astype(int)
    rng = np.random.RandomState(seed)

    selected = []
    for cls in [0, 1]:
        idx = np.where(y == cls)[0]
        if len(idx) < k:
            raise ValueError(f"Not enough samples for k-shot. Need k={k}, got n_cls={len(idx)} (cls={cls})")

        if not KSHOT_UNIQUE_TEXT:
            chosen = rng.choice(idx, size=k, replace=False)
            selected.extend(chosen.tolist())
            continue

        groups = {}
        for i in idx:
            h = _text_hash(X_texts[i])
            groups.setdefault(h, []).append(i)

        keys = list(groups.keys())
        if len(keys) < k:
            raise ValueError(
                f"Not enough UNIQUE texts for k-shot. Need k={k}, got unique={len(keys)} (cls={cls}). "
                f"Set KSHOT_UNIQUE_TEXT=False or reduce k."
            )

        rng.shuffle(keys)
        keys = keys[:k]
        for h in keys:
            selected.append(int(rng.choice(groups[h])))

    selected = np.array(selected, dtype=int)
    rng.shuffle(selected)
    X_sub = [X_texts[i] for i in selected]
    y_sub = y[selected]
    return X_sub, y_sub


def timed_fit(
    model: tf.keras.Model,
    train_inputs,
    train_y,
    dev_inputs,
    dev_y,
    epochs: int,
    batch_size: int,
    verbose: int = 0,
) -> float:
    callbacks = []
    if EARLY_STOP_PATIENCE and EARLY_STOP_PATIENCE > 0:
        callbacks.append(tf.keras.callbacks.EarlyStopping(
            monitor="val_loss",
            patience=EARLY_STOP_PATIENCE,
            restore_best_weights=True,
        ))
    t0 = time.time()
    model.fit(
        train_inputs, train_y,
        validation_data=(dev_inputs, dev_y),
        epochs=epochs,
        batch_size=batch_size,
        verbose=verbose,
        callbacks=callbacks,
        shuffle=True,
    )
    return time.time() - t0


# =========================================================
# 3. Metrics + Threshold calibration
# =========================================================

def select_threshold_macro_f1(y_true: np.ndarray, y_prob: np.ndarray, grid_size: int = THR_GRID_SIZE) -> float:
    y_true = np.asarray(y_true).astype(int)
    y_prob = np.asarray(y_prob).ravel()

    thresholds = np.linspace(0.0, 1.0, grid_size)
    best_thr = 0.5
    best_f1 = -1.0

    for thr in thresholds:
        y_pred = (y_prob >= thr).astype(int)
        f1m = f1_score(y_true, y_pred, average="macro", zero_division=0)
        if f1m > best_f1:
            best_f1 = f1m
            best_thr = float(thr)
    return best_thr

def evaluate_with_threshold(y_true: np.ndarray, y_prob: np.ndarray, thr: float) -> Dict[str, float]:
    y_true = np.asarray(y_true).astype(int)
    y_prob = np.asarray(y_prob).ravel()
    y_pred = (y_prob >= thr).astype(int)

    acc = accuracy_score(y_true, y_pred)
    prec_macro = precision_score(y_true, y_pred, average="macro", zero_division=0)
    rec_macro = recall_score(y_true, y_pred, average="macro", zero_division=0)
    f1_macro = f1_score(y_true, y_pred, average="macro", zero_division=0)
    bce = bce_value(y_true, y_prob)

    return {
        "thr": float(thr),
        "acc": float(acc),
        "prec_macro": float(prec_macro),
        "rec_macro": float(rec_macro),
        "f1_macro": float(f1_macro),
        "bce": float(bce),
    }

def pretty_print_metrics(prefix: str, met: Dict[str, float]):
    print(
        f"{prefix} | thr={met['thr']:.3f}  "
        f"Acc={met['acc']:.4f}  MacroF1={met['f1_macro']:.4f}  BCE={met['bce']:.4f}"
    )


# =========================================================
# 4. Models (multi-head)
# =========================================================

def make_optimizer(lr: float) -> tf.keras.optimizers.Optimizer:
    return tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1.0)

def build_plain_cnn_mh(vocab_size: int) -> Model:
    """
    Plain CNN with domain-specific heads:
      shared: emb, conv, shared_fc
      heads: head0 (political), head1 (medical)
    """
    tok_in = L.Input(shape=(MAXLEN,), dtype="int32", name="tokens")
    dom_in = L.Input(shape=(), dtype="int32", name="domain_id")  # 0 or 1

    x = L.Embedding(vocab_size, EMBED_DIM, name="emb")(tok_in)
    h = L.Conv1D(CONV_FILTERS, KERNEL_SIZE, activation="relu", padding="same", name="conv")(x)
    pooled = L.GlobalMaxPooling1D(name="gmp")(h)

    z = L.Dense(DENSE_UNITS, activation="relu", name="shared_fc")(pooled)
    z = L.Dropout(DROPOUT, name="drop")(z)

    logit0 = L.Dense(1, activation=None, name="head0")(z)
    logit1 = L.Dense(1, activation=None, name="head1")(z)

    domf = L.Lambda(lambda d: tf.cast(tf.reshape(d, (-1, 1)), tf.float32), name="dom_float")(dom_in)
    logit = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_head")([domf, logit0, logit1])

    out = L.Activation("sigmoid", name="out")(logit)
    model = Model(inputs={"tokens": tok_in, "domain_id": dom_in}, outputs=out, name="PlainCNN_MH")
    model.compile(optimizer=make_optimizer(LR_SOURCE), loss="binary_crossentropy")
    return model


def _tn(std=0.02):
    return tf.keras.initializers.TruncatedNormal(stddev=std)

def build_daeewc_cnn_mh(vocab_size: int) -> Model:
    """
    DAEWC CNN:
      - shared backbone: emb, conv, shared_fc
      - domain-specific adapters: after conv (sequence) and after shared_fc (vector)
      - domain-specific gates: after conv and after shared_fc
      - domain-specific heads: head0/head1
    IMPORTANT:
      - adapters are identity-initialized: up-proj = zeros => initial adapter output=0
      - gates are identity-initialized: last gate layer = zeros, gate = 2*sigmoid => initial gate=1
    """

    tok_in = L.Input(shape=(MAXLEN,), dtype="int32", name="tokens")
    dom_in = L.Input(shape=(), dtype="int32", name="domain_id")  # 0 or 1

    # -------- shared backbone --------
    x = L.Embedding(vocab_size, EMBED_DIM, name="emb")(tok_in)
    h = L.Conv1D(CONV_FILTERS, KERNEL_SIZE, activation="relu", padding="same", name="conv")(x)

    # =====================================================
    # (A) Adapter after conv: per-domain
    # =====================================================
    # domain 0 adapter
    a0 = L.TimeDistributed(
        L.Dense(ADAPTER_R, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros"),
        name="adp0_conv_down"
    )(h)
    a0 = L.TimeDistributed(
        L.Dense(CONV_FILTERS, activation=None, kernel_initializer="zeros", bias_initializer="zeros"),
        name="adp0_conv_up"
    )(a0)

    # domain 1 adapter
    a1 = L.TimeDistributed(
        L.Dense(ADAPTER_R, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros"),
        name="adp1_conv_down"
    )(h)
    a1 = L.TimeDistributed(
        L.Dense(CONV_FILTERS, activation=None, kernel_initializer="zeros", bias_initializer="zeros"),
        name="adp1_conv_up"
    )(a1)

    domf3 = L.Lambda(lambda d: tf.cast(tf.reshape(d, (-1, 1, 1)), tf.float32), name="dom_float3")(dom_in)
    a = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_conv_adapter")([domf3, a0, a1])

    h = L.Add(name="conv_adapter_residual")([h, a])

    # =====================================================
    # (B) Gate after conv: per-domain (SE/FiLM style)
    # gate = 2*sigmoid(preact)  => preact=0 -> gate=1 (identity)
    # =====================================================
    s_conv = L.GlobalAveragePooling1D(name="gap_conv")(h)

    g0 = L.Dense(GATE_HIDDEN, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="gate0_conv_fc1")(s_conv)
    g0 = L.Dense(CONV_FILTERS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="gate0_conv_fc2")(g0)

    g1 = L.Dense(GATE_HIDDEN, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="gate1_conv_fc1")(s_conv)
    g1 = L.Dense(CONV_FILTERS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="gate1_conv_fc2")(g1)

    domf2 = L.Lambda(lambda d: tf.cast(tf.reshape(d, (-1, 1)), tf.float32), name="dom_float2")(dom_in)
    g_preact = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_conv_gate_preact")([domf2, g0, g1])

    g = L.Activation("sigmoid", name="conv_gate_sigmoid")(g_preact)
    g = L.Lambda(lambda u: 2.0 * u, name="conv_gate_scale2")(g)          # (0,2)
    g = L.Reshape((1, CONV_FILTERS), name="conv_gate_reshape")(g)

    h = L.Multiply(name="conv_gated")([h, g])

    pooled = L.GlobalMaxPooling1D(name="gmp")(h)

    z = L.Dense(DENSE_UNITS, activation="relu", name="shared_fc")(pooled)

    # =====================================================
    # (C) Adapter after shared_fc (vector): per-domain
    # =====================================================
    va0 = L.Dense(ADAPTER_R, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="adp0_fc_down")(z)
    va0 = L.Dense(DENSE_UNITS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="adp0_fc_up")(va0)

    va1 = L.Dense(ADAPTER_R, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="adp1_fc_down")(z)
    va1 = L.Dense(DENSE_UNITS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="adp1_fc_up")(va1)

    va = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_fc_adapter")([domf2, va0, va1])
    z = L.Add(name="fc_adapter_residual")([z, va])

    # =====================================================
    # (D) Gate after shared_fc (vector): per-domain
    # =====================================================
    gz0 = L.Dense(GATE_HIDDEN, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="gate0_fc_fc1")(z)
    gz0 = L.Dense(DENSE_UNITS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="gate0_fc_fc2")(gz0)

    gz1 = L.Dense(GATE_HIDDEN, activation="relu", kernel_initializer=_tn(), bias_initializer="zeros", name="gate1_fc_fc1")(z)
    gz1 = L.Dense(DENSE_UNITS, activation=None, kernel_initializer="zeros", bias_initializer="zeros", name="gate1_fc_fc2")(gz1)

    gz_preact = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_fc_gate_preact")([domf2, gz0, gz1])
    gz = L.Activation("sigmoid", name="fc_gate_sigmoid")(gz_preact)
    gz = L.Lambda(lambda u: 2.0 * u, name="fc_gate_scale2")(gz)
    z = L.Multiply(name="fc_gated")([z, gz])

    z = L.Dropout(DROPOUT, name="drop")(z)

    logit0 = L.Dense(1, activation=None, name="head0")(z)
    logit1 = L.Dense(1, activation=None, name="head1")(z)

    logit = L.Lambda(lambda t: (1.0 - t[0]) * t[1] + t[0] * t[2], name="select_head")([domf2, logit0, logit1])
    out = L.Activation("sigmoid", name="out")(logit)

    model = Model(inputs={"tokens": tok_in, "domain_id": dom_in}, outputs=out, name="DAEWC_CNN_MH")
    model.compile(optimizer=make_optimizer(LR_SOURCE), loss="binary_crossentropy")
    return model


# =========================================================
# 5. Trainable strategies + weight copying
# =========================================================

def layer_by_name(model: Model, name: str) -> L.Layer:
    for layer in model.layers:
        if layer.name == name:
            return layer
    raise KeyError(f"Layer {name} not found")

def set_trainable_plain_source(model: Model):
    # train backbone + head0
    for layer in model.layers:
        layer.trainable = True
    layer_by_name(model, "head1").trainable = False

def set_trainable_plain_target_full(model: Model):
    # train backbone + head1, freeze head0
    for layer in model.layers:
        layer.trainable = True
    layer_by_name(model, "head0").trainable = False

def set_trainable_plain_target_backbone_frozen(model: Model):
    # only head1
    for layer in model.layers:
        layer.trainable = False
    layer_by_name(model, "head1").trainable = True

def copy_backbone_and_head0_from_plain(plain: Model, dae: Model):
    """
    Copy backbone weights (emb/conv/shared_fc) and source head0 from plain -> dae.
    DAEWC adapters/gates are identity-init, so dae starts functionally identical to plain on domain0.
    """
    for lname in ["emb", "conv", "shared_fc", "head0"]:
        dae.get_layer(lname).set_weights(plain.get_layer(lname).get_weights())

def set_trainable_daeewc_target_stage1(dae: Model):
    """
    Stage1: train only domain1 adapters + gates + head1.
    Backbone frozen.
    """
    for layer in dae.layers:
        layer.trainable = False

    # train domain1 modules + head1
    train_names = [
        "adp1_conv_down", "adp1_conv_up",
        "gate1_conv_fc1", "gate1_conv_fc2",
        "adp1_fc_down", "adp1_fc_up",
        "gate1_fc_fc1", "gate1_fc_fc2",
        "head1",
    ]
    for n in train_names:
        layer_by_name(dae, n).trainable = True

def set_trainable_daeewc_target_stage2(dae: Model, unfreeze_backbone: Tuple[str, ...] = ("shared_fc",)):
    """
    Stage2: keep domain1 modules trainable; unfreeze small subset of backbone layers
    (e.g., shared_fc, optionally conv) for controlled update under EWC.
    """
    set_trainable_daeewc_target_stage1(dae)
    for lname in unfreeze_backbone:
        layer_by_name(dae, lname).trainable = True
    # (emb usually stays frozen for stability; if you want, add "emb" here)


# =========================================================
# 6. Fisher + EWC wrapper
# =========================================================

def smooth_labels_binary(y: tf.Tensor, smooth: float) -> tf.Tensor:
    y = tf.cast(y, tf.float32)
    return y * (1.0 - smooth) + 0.5 * smooth

def backbone_protected_vars(model: Model, backbone_layer_names: Tuple[str, ...]) -> List[tf.Variable]:
    """
    Return list of backbone variables to protect with EWC.
    If EWC_PROTECT_BIAS=False, exclude biases.
    """
    vars_ = []
    for lname in backbone_layer_names:
        layer = layer_by_name(model, lname)
        for v in layer.trainable_variables:
            if (not EWC_PROTECT_BIAS) and v.name.endswith("bias:0"):
                continue
            vars_.append(v)
    return vars_

def snapshot_vars(var_list: List[tf.Variable]) -> Dict[str, tf.Tensor]:
    return {v.name: tf.identity(v) for v in var_list}

def compute_fisher_diagonal(
    model: Model,
    X_tokens: np.ndarray,
    y: np.ndarray,
    domain_arr: np.ndarray,
    var_list: List[tf.Variable],
    max_samples: int,
    batch_size: int,
    label_smooth: float,
    training_true: bool,
    seed: int,
) -> Tuple[Dict[str, tf.Tensor], float, float]:
    """
    Returns fisher_dict, fisher_mean, elapsed_seconds
    """
    rng = np.random.RandomState(seed)
    n_total = len(y)
    n = min(n_total, int(max_samples))
    idx = rng.choice(n_total, size=n, replace=False)

    Xt = X_tokens[idx]
    dt = domain_arr[idx].astype(np.int32)
    yt = y[idx].astype(np.float32).reshape(-1, 1)

    ds = tf.data.Dataset.from_tensor_slices(({"tokens": Xt, "domain_id": dt}, yt)).batch(batch_size)

    fisher = {v.name: tf.zeros_like(v) for v in var_list}
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction="none")
    total = tf.constant(0, dtype=tf.int32)

    t0 = time.time()
    for x_b, y_b in ds:
        y_b = tf.cast(y_b, tf.float32)
        y_b = tf.reshape(y_b, (-1, 1))
        y_s = smooth_labels_binary(y_b, label_smooth)

        with tf.GradientTape() as tape:
            y_pred = model(x_b, training=training_true)
            nll = tf.reduce_sum(bce(y_s, y_pred))  # sum

        grads = tape.gradient(nll, var_list)
        bs = tf.shape(y_b)[0]
        total += bs

        for v, g in zip(var_list, grads):
            if g is not None:
                fisher[v.name] = fisher[v.name] + tf.square(g)

    total_f = tf.cast(total, next(iter(fisher.values())).dtype)
    for name in fisher:
        fisher[name] = fisher[name] / (total_f + 1e-12)

    fisher_mean = float(np.mean([float(tf.reduce_mean(v).numpy()) for v in fisher.values()])) if fisher else 0.0
    t_elapsed = time.time() - t0
    return fisher, fisher_mean, t_elapsed


class CLWrapper(tf.keras.Model):
    """
    Wrapper adding:
      - backbone-only EWC on variables in fisher/theta_old
      - optional proximity term (also on theta_old vars)
      - gradient scaling on protected vars (backbone_lr_mult)
    """
    def __init__(
        self,
        base_model: Model,
        fisher: Optional[Dict[str, tf.Tensor]],
        theta_old: Optional[Dict[str, tf.Tensor]],
        ewc_lambda: float,
        prox_alpha: float,
        protected_var_names: Optional[set],
        backbone_lr_mult: float,
    ):
        super().__init__()
        self.base = base_model
        self.fisher = fisher or {}
        self.theta_old = theta_old or {}
        self.ewc_lambda = float(ewc_lambda)
        self.prox_alpha = float(prox_alpha)
        self.protected_var_names = protected_var_names or set()
        self.backbone_lr_mult = float(backbone_lr_mult)

    def call(self, inputs, training=False):
        return self.base(inputs, training=training)

    def train_step(self, data):
        x, y = data
        y = tf.cast(y, tf.float32)
        y = tf.reshape(y, (-1, 1))

        vars_all = self.base.trainable_variables

        with tf.GradientTape() as tape:
            y_pred = self.base(x, training=True)
            loss = self.compiled_loss(y, y_pred, regularization_losses=self.base.losses)

            # EWC penalty
            if self.ewc_lambda > 0.0 and self.fisher:
                ewc_pen = tf.constant(0.0, dtype=loss.dtype)
                for v in vars_all:
                    if v.name in self.fisher:
                        delta = v - self.theta_old[v.name]
                        ewc_pen += tf.reduce_sum(self.fisher[v.name] * tf.square(delta))
                loss = loss + 0.5 * self.ewc_lambda * ewc_pen

            # Proximity penalty
            if self.prox_alpha > 0.0 and self.theta_old:
                prox = tf.constant(0.0, dtype=loss.dtype)
                for v in vars_all:
                    if v.name in self.theta_old:
                        delta = v - self.theta_old[v.name]
                        prox += tf.reduce_sum(tf.square(delta))
                loss = loss + 0.5 * self.prox_alpha * prox

        grads = tape.gradient(loss, vars_all)

        # scale protected backbone grads
        if self.backbone_lr_mult != 1.0 and self.protected_var_names:
            new_grads = []
            for g, v in zip(grads, vars_all):
                if g is None:
                    new_grads.append(None)
                    continue
                if v.name in self.protected_var_names:
                    new_grads.append(g * self.backbone_lr_mult)
                else:
                    new_grads.append(g)
            grads = new_grads

        self.optimizer.apply_gradients(zip(grads, vars_all))
        return {"loss": loss}


# =========================================================
# 7. Load datasets
# =========================================================
print("Loading datasets...")

fake_df = pd.read_csv(PATH_FAKE)
real_df = pd.read_csv(PATH_REAL)
covid_fake_df = pd.read_csv(PATH_COVID_FAKE)
covid_real_df = pd.read_csv(PATH_COVID_REAL)

# Political (ISOT subset)
pol_fake = fake_df[(fake_df["subject"] == "politics") & (fake_df["text"].astype(str).str.len() >= MIN_CHAR_LEN)]["text"].astype(str)
pol_real = real_df[(real_df["subject"] == "politicsNews") & (real_df["text"].astype(str).str.len() >= MIN_CHAR_LEN)]["text"].astype(str)

pol_texts = [basic_clean(x) for x in pd.concat([pol_fake, pol_real]).tolist()]
pol_labels = np.concatenate([
    np.zeros(len(pol_fake), dtype=int),
    np.ones(len(pol_real), dtype=int),
])

print(f"Political | fake={len(pol_fake)}  real={len(pol_real)}  total={len(pol_texts)}")

# Medical (COVID dataset)
col_f = pick_text_col(covid_fake_df)
col_r = pick_text_col(covid_real_df)

med_fake = covid_fake_df[covid_fake_df[col_f].astype(str).str.len() >= MIN_CHAR_LEN][col_f].astype(str)
med_real = covid_real_df[covid_real_df[col_r].astype(str).str.len() >= MIN_CHAR_LEN][col_r].astype(str)

med_texts = [basic_clean(x) for x in pd.concat([med_fake, med_real]).tolist()]
med_labels = np.concatenate([
    np.zeros(len(med_fake), dtype=int),
    np.ones(len(med_real), dtype=int),
])

print(f"Medical   | fake={len(med_fake)}  real={len(med_real)}  total={len(med_texts)}")

# Optional: cross-domain exact dedup (paper-style leakage control)
if CROSS_DOMAIN_DEDUP:
    pol_hash = set(_text_hash(t) for t in pol_texts)
    keep_mask = np.array([_text_hash(t) not in pol_hash for t in med_texts], dtype=bool)
    removed = int(np.sum(~keep_mask))
    if removed > 0:
        med_texts = [t for t, k in zip(med_texts, keep_mask) if k]
        med_labels = med_labels[keep_mask]
    print(f"CROSS_DOMAIN_DEDUP: removed {removed} target samples that duplicate source (normalized hash).")


# =========================================================
# 8. Split train/dev/test (fixed)
# =========================================================

X_pol_train_texts, X_pol_dev_texts, X_pol_test_texts, y_pol_train, y_pol_dev, y_pol_test = split_train_dev_test(
    pol_texts, pol_labels, seed=DATA_SPLIT_SEED, test_size=TEST_SIZE, dev_size=DEV_SIZE
)
X_med_train_texts, X_med_dev_texts, X_med_test_texts, y_med_train_full, y_med_dev, y_med_test = split_train_dev_test(
    med_texts, med_labels, seed=DATA_SPLIT_SEED, test_size=TEST_SIZE, dev_size=DEV_SIZE
)

print("\nSplit sizes:")
print(f"Political: train={len(X_pol_train_texts)}  dev={len(X_pol_dev_texts)}  test={len(X_pol_test_texts)}")
print(f"Medical  : train={len(X_med_train_texts)}  dev={len(X_med_dev_texts)}  test={len(X_med_test_texts)}")


# =========================================================
# 9. Tokenizer (source-only or union)
# =========================================================

if TOKENIZER_MODE == "source":
    tok_texts = X_pol_train_texts
    print("\nTokenizer mode: SOURCE-only (paper-strict)")
elif TOKENIZER_MODE == "union":
    tok_texts = X_pol_train_texts + X_med_train_texts
    print("\nTokenizer mode: UNION (source_train + target_train texts)")
else:
    raise ValueError("TOKENIZER_MODE must be 'source' or 'union'")

TOK, VOCAB_SIZE = build_tokenizer(tok_texts, MAX_NUM_WORDS)
print(f"Vocab size = {VOCAB_SIZE} (cap={MAX_NUM_WORDS})")

# Vectorize all splits once
X_pol_train = vectorize(TOK, X_pol_train_texts, MAXLEN)
X_pol_dev = vectorize(TOK, X_pol_dev_texts, MAXLEN)
X_pol_test = vectorize(TOK, X_pol_test_texts, MAXLEN)

X_med_train_full = vectorize(TOK, X_med_train_texts, MAXLEN)
X_med_dev = vectorize(TOK, X_med_dev_texts, MAXLEN)
X_med_test = vectorize(TOK, X_med_test_texts, MAXLEN)

D_pol_train = domain_ids(len(X_pol_train), 0)
D_pol_dev = domain_ids(len(X_pol_dev), 0)
D_pol_test = domain_ids(len(X_pol_test), 0)

D_med_dev = domain_ids(len(X_med_dev), 1)
D_med_test = domain_ids(len(X_med_test), 1)


# =========================================================
# 10. Pretrain + Fisher (Stage A)
# =========================================================

@dataclass
class SourceArtifacts:
    weights_plain: List[np.ndarray]
    thr_pol: float
    src_f1_pre_test: float
    src_f1_pre_dev: float
    fisher: Dict[str, tf.Tensor]
    theta_old: Dict[str, tf.Tensor]
    fisher_mean: float
    time_pre: float
    time_fisher: float
    protected_var_names: set

def pretrain_and_fisher(seed: int) -> SourceArtifacts:
    clear_tf()
    reset_seeds(seed)
    print("\n[Stage A] Pretrain Plain backbone on Political (domain=0)")

    plain = build_plain_cnn_mh(VOCAB_SIZE)
    set_trainable_plain_source(plain)
    plain.compile(optimizer=make_optimizer(LR_SOURCE), loss="binary_crossentropy")

    t0 = time.time()
    plain.fit(
        {"tokens": X_pol_train, "domain_id": D_pol_train},
        y_pol_train,
        validation_data=({"tokens": X_pol_dev, "domain_id": D_pol_dev}, y_pol_dev),
        epochs=EPOCHS_SOURCE,
        batch_size=BATCH_SIZE_SOURCE,
        verbose=0,
        shuffle=True,
    )
    time_pre = time.time() - t0

    # Calibrate threshold on source DEV
    pol_dev_prob = plain.predict({"tokens": X_pol_dev, "domain_id": D_pol_dev}, verbose=0).ravel()
    thr_pol = select_threshold_macro_f1(y_pol_dev, pol_dev_prob) if CALIBRATE_THR_ON_DEV else 0.5
    met_pol_dev = evaluate_with_threshold(y_pol_dev, pol_dev_prob, thr_pol)

    # Source TEST (pre)
    pol_test_prob = plain.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
    met_pol_test = evaluate_with_threshold(y_pol_test, pol_test_prob, thr_pol)

    pretty_print_metrics("Political DEV (Plain pre)", met_pol_dev)
    pretty_print_metrics("Political TEST (Plain pre)", met_pol_test)

    # Fisher on protected backbone vars (emb/conv/shared_fc, excluding bias by default)
    fisher, theta_old, fisher_mean, time_fisher = {}, {}, 0.0, 0.0
    protected_names = set()
    if USE_EWC:
        backbone_layers = ("emb", "conv", "shared_fc")
        var_list = backbone_protected_vars(plain, backbone_layers)
        protected_names = set([v.name for v in var_list])

        fisher, fisher_mean, time_fisher = compute_fisher_diagonal(
            model=plain,
            X_tokens=X_pol_train,
            y=y_pol_train,
            domain_arr=D_pol_train,
            var_list=var_list,
            max_samples=FISHER_SAMPLES,
            batch_size=FISHER_BATCH_SIZE,
            label_smooth=FISHER_LABEL_SMOOTH,
            training_true=FISHER_TRAINING_TRUE,
            seed=seed,
        )
        theta_old = snapshot_vars(var_list)
        print(f"Fisher mean={fisher_mean:.6e}  fisher_time={time_fisher:.2f}s  protected_vars={len(protected_names)}")

    return SourceArtifacts(
        weights_plain=plain.get_weights(),
        thr_pol=thr_pol,
        src_f1_pre_test=met_pol_test["f1_macro"],
        src_f1_pre_dev=met_pol_dev["f1_macro"],
        fisher=fisher,
        theta_old=theta_old,
        fisher_mean=fisher_mean,
        time_pre=time_pre,
        time_fisher=time_fisher,
        protected_var_names=protected_names,
    )


# =========================================================
# 11. Eval helper
# =========================================================

def eval_domain(
    model: Model,
    X_dev: np.ndarray, y_dev: np.ndarray, D_dev: np.ndarray,
    X_test: np.ndarray, y_test: np.ndarray, D_test: np.ndarray,
) -> Tuple[float, Dict[str, float], Dict[str, float]]:
    prob_dev = model.predict({"tokens": X_dev, "domain_id": D_dev}, verbose=0).ravel()
    thr = select_threshold_macro_f1(y_dev, prob_dev) if CALIBRATE_THR_ON_DEV else 0.5
    met_dev = evaluate_with_threshold(y_dev, prob_dev, thr)

    prob_test = model.predict({"tokens": X_test, "domain_id": D_test}, verbose=0).ravel()
    met_test = evaluate_with_threshold(y_test, prob_test, thr)
    return thr, met_dev, met_test


# =========================================================
# 12. Run all experiments (Stage B)
# =========================================================

records: List[Dict] = []

def add_record(
    seed: int,
    shot: int,
    method: str,
    met_tgt_test: Dict[str, float],
    met_src_test_after: Dict[str, float],
    src_f1_pre: float,
    src_thr_pre: float,
    trainable_params: int,
    t_pretrain: float,
    t_fisher: float,
    t_adapt: float,
):
    forget_f1 = float(src_f1_pre - met_src_test_after["f1_macro"])
    avg_f1 = 0.5 * float(met_tgt_test["f1_macro"] + met_src_test_after["f1_macro"])
    records.append({
        "seed": seed,
        "shot": shot,
        "method": method,
        "tgt_acc": met_tgt_test["acc"],
        "tgt_f1_macro": met_tgt_test["f1_macro"],
        "tgt_bce": met_tgt_test["bce"],
        "src_thr_pre": src_thr_pre,
        "src_f1_pre": src_f1_pre,
        "src_acc_after": met_src_test_after["acc"],
        "src_f1_after": met_src_test_after["f1_macro"],
        "src_bce_after": met_src_test_after["bce"],
        "forget_f1": forget_f1,
        "avg_f1_after": avg_f1,
        "trainable_params": trainable_params,
        "t_pretrain": t_pretrain,
        "t_fisher": t_fisher,
        "t_adapt": t_adapt,
        "t_total_once": float(t_pretrain + t_fisher + t_adapt),
    })

def summarize_and_save(df: pd.DataFrame):
    df.to_csv(OUT_RAW_CSV, index=False)
    print(f"\nSaved raw: {OUT_RAW_CSV}")

    def mean_ci(x: np.ndarray) -> Tuple[float, float]:
        x = np.asarray(x, dtype=float)
        n = len(x)
        if n <= 1:
            return float(np.mean(x)), 0.0
        m = float(np.mean(x))
        s = float(np.std(x, ddof=1))
        ci = 1.96 * s / np.sqrt(n)
        return m, ci

    rows = []
    for (shot, method), g in df.groupby(["shot", "method"]):
        m_f1, ci_f1 = mean_ci(g["tgt_f1_macro"].values)
        m_forget, ci_forget = mean_ci(g["forget_f1"].values)
        m_time, ci_time = mean_ci(g["t_adapt"].values)
        m_params = float(g["trainable_params"].iloc[0])
        rows.append({
            "shot": shot,
            "method": method,
            "tgt_f1_macro_mean": m_f1,
            "tgt_f1_macro_ci95": ci_f1,
            "forget_f1_mean": m_forget,
            "forget_f1_ci95": ci_forget,
            "adapt_time_mean_s": m_time,
            "adapt_time_ci95": ci_time,
            "trainable_params": m_params,
        })
    df_sum = pd.DataFrame(rows).sort_values(["shot", "method"])
    df_sum.to_csv(OUT_SUMMARY_CSV, index=False)
    print(f"Saved summary: {OUT_SUMMARY_CSV}")

    print("\n=== Pivot: Target Macro-F1 (mean) ===")
    print(df_sum.pivot(index="shot", columns="method", values="tgt_f1_macro_mean"))

    print("\n=== Pivot: Forgetting (Î”Src Macro-F1; lower is better) ===")
    print(df_sum.pivot(index="shot", columns="method", values="forget_f1_mean"))

    print("\n=== Pivot: Adapt time (s, mean) ===")
    print(df_sum.pivot(index="shot", columns="method", values="adapt_time_mean_s"))


# Main loop
for seed in SEEDS:
    print("\n" + "#" * 120)
    print(f"RUN seed={seed}")
    reset_seeds(seed)

    # Stage A: pretrain + fisher
    art = pretrain_and_fisher(seed)

    # Pre source test F1 is in art.src_f1_pre_test
    src_f1_pre_plain = art.src_f1_pre_test

    # Build a plain model instance for transfers (so we can set_weights repeatedly)
    clear_tf()
    reset_seeds(seed)
    plain_template = build_plain_cnn_mh(VOCAB_SIZE)
    plain_template.set_weights(art.weights_plain)

    # =========================================================
    # Loop over k-shot
    # =========================================================
    for k in SHOTS_PER_CLASS_LIST:
        # Sample target few-shot set from medical TRAIN (fixed sampling seed)
        X_med_sub_texts, y_med_sub = sample_k_shot_per_class(
            X_med_train_texts, y_med_train_full, k, seed=KSHOT_SAMPLE_SEED
        )
        X_med_sub = vectorize(TOK, X_med_sub_texts, MAXLEN)
        D_med_sub = domain_ids(len(X_med_sub), 1)

        print("\n" + "-" * 110)
        print(f"Target setting: {k}-shot/class  (n={len(X_med_sub)})")

        # =========================================================
        # Baseline: From-scratch on target (Plain)
        # =========================================================
        if INCLUDE_SCRATCH:
            print("\n[Scratch-Plain]")
            clear_tf()
            reset_seeds(seed)

            m = build_plain_cnn_mh(VOCAB_SIZE)
            for layer in m.layers:
                layer.trainable = True
            m.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

            t_adapt = timed_fit(
                m,
                {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
                {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                epochs=EPOCHS_TARGET_STAGE1,  # same budget as stage1
                batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
                verbose=0,
            )

            _, _, met_med_test = eval_domain(m, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
            pretty_print_metrics("Medical TEST (Scratch-Plain)", met_med_test)

            records.append({
                "seed": seed,
                "shot": k,
                "method": "Scratch-Plain",
                "tgt_acc": met_med_test["acc"],
                "tgt_f1_macro": met_med_test["f1_macro"],
                "tgt_bce": met_med_test["bce"],
                "src_thr_pre": np.nan,
                "src_f1_pre": np.nan,
                "src_acc_after": np.nan,
                "src_f1_after": np.nan,
                "src_bce_after": np.nan,
                "forget_f1": np.nan,
                "avg_f1_after": np.nan,
                "trainable_params": count_trainable_params(m),
                "t_pretrain": 0.0,
                "t_fisher": 0.0,
                "t_adapt": t_adapt,
                "t_total_once": t_adapt,
            })

        # =========================================================
        # Transfer: Plain Full FT (head0 frozen)
        # =========================================================
        print("\n[Transfer-Plain FullFT]")
        clear_tf()
        reset_seeds(seed)

        m = build_plain_cnn_mh(VOCAB_SIZE)
        m.set_weights(art.weights_plain)
        set_trainable_plain_target_full(m)
        m.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

        t_adapt = timed_fit(
            m,
            {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
            {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
            epochs=EPOCHS_TARGET_STAGE1,
            batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
            verbose=0,
        )

        _, _, met_med_test = eval_domain(m, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
        pretty_print_metrics("Medical TEST (Transfer-Plain)", met_med_test)

        # Source AFTER (fixed threshold from source dev)
        pol_test_prob_after = m.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
        met_src_after = evaluate_with_threshold(y_pol_test, pol_test_prob_after, art.thr_pol)
        pretty_print_metrics("Political TEST after (Transfer-Plain)", met_src_after)

        add_record(
            seed=seed,
            shot=k,
            method="Transfer-Plain",
            met_tgt_test=met_med_test,
            met_src_test_after=met_src_after,
            src_f1_pre=src_f1_pre_plain,
            src_thr_pre=art.thr_pol,
            trainable_params=count_trainable_params(m),
            t_pretrain=art.time_pre,
            t_fisher=0.0,
            t_adapt=t_adapt,
        )

        # =========================================================
        # Transfer: Plain + EWC (backbone-only)
        # =========================================================
        if INCLUDE_PLAIN_EWC and USE_EWC:
            print("\n[Transfer-Plain + EWC]")
            clear_tf()
            reset_seeds(seed)

            base = build_plain_cnn_mh(VOCAB_SIZE)
            base.set_weights(art.weights_plain)
            set_trainable_plain_target_full(base)

            wrapper = CLWrapper(
                base_model=base,
                fisher=art.fisher,
                theta_old=art.theta_old,
                ewc_lambda=EWC_LAMBDA,
                prox_alpha=PROX_ALPHA,
                protected_var_names=art.protected_var_names,
                backbone_lr_mult=1.0,  # plain EWC baseline: no special scaling
            )
            wrapper.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

            t_adapt = timed_fit(
                wrapper,
                {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
                {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                epochs=EPOCHS_TARGET_STAGE1,
                batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
                verbose=0,
            )

            _, _, met_med_test = eval_domain(wrapper, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
            pretty_print_metrics("Medical TEST (Plain+EWC)", met_med_test)

            pol_test_prob_after = wrapper.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
            met_src_after = evaluate_with_threshold(y_pol_test, pol_test_prob_after, art.thr_pol)
            pretty_print_metrics("Political TEST after (Plain+EWC)", met_src_after)

            add_record(
                seed=seed,
                shot=k,
                method="Transfer-Plain+EWC",
                met_tgt_test=met_med_test,
                met_src_test_after=met_src_after,
                src_f1_pre=src_f1_pre_plain,
                src_thr_pre=art.thr_pol,
                trainable_params=count_trainable_params(base),
                t_pretrain=art.time_pre,
                t_fisher=art.time_fisher,
                t_adapt=t_adapt,
            )

        # =========================================================
        # Adapter-only baseline (DAEWC model; backbone frozen)
        # =========================================================
        if INCLUDE_ADAPTER_ONLY:
            print("\n[Adapter-Only (DAEWC; backbone frozen)]")
            clear_tf()
            reset_seeds(seed)

            plain_src = build_plain_cnn_mh(VOCAB_SIZE)
            plain_src.set_weights(art.weights_plain)

            dae = build_daeewc_cnn_mh(VOCAB_SIZE)
            copy_backbone_and_head0_from_plain(plain_src, dae)

            set_trainable_daeewc_target_stage1(dae)  # stage1 == adapter-only
            dae.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

            t_adapt = timed_fit(
                dae,
                {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
                {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                epochs=EPOCHS_TARGET_STAGE1,
                batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
                verbose=0,
            )

            _, _, met_med_test = eval_domain(dae, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
            pretty_print_metrics("Medical TEST (Adapter-Only)", met_med_test)

            pol_test_prob_after = dae.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
            met_src_after = evaluate_with_threshold(y_pol_test, pol_test_prob_after, art.thr_pol)
            pretty_print_metrics("Political TEST after (Adapter-Only)", met_src_after)

            add_record(
                seed=seed,
                shot=k,
                method="Adapter-Only",
                met_tgt_test=met_med_test,
                met_src_test_after=met_src_after,
                src_f1_pre=src_f1_pre_plain,
                src_thr_pre=art.thr_pol,
                trainable_params=count_trainable_params(dae),
                t_pretrain=art.time_pre,
                t_fisher=0.0,
                t_adapt=t_adapt,
            )

        # =========================================================
        # DAEWC (Stage1 + Stage2 with backbone-only EWC)
        # =========================================================
        if INCLUDE_DAEWC and USE_EWC:
            print("\n[DAEWC (Stage1 + Stage2)]")
            clear_tf()
            reset_seeds(seed)

            plain_src = build_plain_cnn_mh(VOCAB_SIZE)
            plain_src.set_weights(art.weights_plain)

            dae = build_daeewc_cnn_mh(VOCAB_SIZE)
            copy_backbone_and_head0_from_plain(plain_src, dae)

            # ---- Stage1: adapters/gates/head1 only ----
            set_trainable_daeewc_target_stage1(dae)
            dae.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")
            t_stage1 = timed_fit(
                dae,
                {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
                {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                epochs=EPOCHS_TARGET_STAGE1,
                batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
                verbose=0,
            )

            # Decide which backbone parts to unfreeze in stage2 (shot-aware)
            if k <= 20:
                unfreeze = ("shared_fc",)          # safer when extremely few-shot
            else:
                unfreeze = ("conv", "shared_fc")   # allow a bit more plasticity

            # ---- Stage2: small backbone update under EWC + gentle grad scaling ----
            best_lambda = EWC_LAMBDA
            best_score = -1e9
            best_weights = None

            # Save stage1 weights as starting point for each lambda trial
            w_stage1 = dae.get_weights()

            lambda_grid = DAEWC_LAMBDA_GRID if AUTO_TUNE_DAEWC_LAMBDA else [EWC_LAMBDA]

            for lam in lambda_grid:
                # restore stage1 state
                dae.set_weights(w_stage1)

                set_trainable_daeewc_target_stage2(dae, unfreeze_backbone=unfreeze)

                wrapper = CLWrapper(
                    base_model=dae,
                    fisher=art.fisher,
                    theta_old=art.theta_old,
                    ewc_lambda=lam,
                    prox_alpha=PROX_ALPHA,
                    protected_var_names=art.protected_var_names,
                    backbone_lr_mult=BACKBONE_LR_MULT,
                )
                wrapper.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

                _ = timed_fit(
                    wrapper,
                    {"tokens": X_med_sub, "domain_id": D_med_sub}, y_med_sub,
                    {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                    epochs=EPOCHS_TARGET_STAGE2,
                    batch_size=min(BATCH_SIZE_TARGET, len(X_med_sub)),
                    verbose=0,
                )

                # DEV-based selection (no test leakage)
                # target dev score
                prob_med_dev = wrapper.predict({"tokens": X_med_dev, "domain_id": D_med_dev}, verbose=0).ravel()
                thr_med = select_threshold_macro_f1(y_med_dev, prob_med_dev) if CALIBRATE_THR_ON_DEV else 0.5
                met_med_dev = evaluate_with_threshold(y_med_dev, prob_med_dev, thr_med)

                # source dev retention (use fixed source thr)
                prob_pol_dev_after = wrapper.predict({"tokens": X_pol_dev, "domain_id": D_pol_dev}, verbose=0).ravel()
                met_pol_dev_after = evaluate_with_threshold(y_pol_dev, prob_pol_dev_after, art.thr_pol)
                src_drop = float(art.src_f1_pre_dev - met_pol_dev_after["f1_macro"])

                penalty = 0.0
                if src_drop > TUNE_FORGET_TOL:
                    penalty = TUNE_BETA_FORGET * (src_drop - TUNE_FORGET_TOL)

                score = float(met_med_dev["f1_macro"] - penalty)

                if score > best_score:
                    best_score = score
                    best_lambda = lam
                    best_weights = dae.get_weights()

            # restore best lambda weights
            dae.set_weights(best_weights)
            # rebuild wrapper for final evaluation (so predict uses the same object)
            set_trainable_daeewc_target_stage2(dae, unfreeze_backbone=unfreeze)
            wrapper = CLWrapper(
                base_model=dae,
                fisher=art.fisher,
                theta_old=art.theta_old,
                ewc_lambda=best_lambda,
                prox_alpha=PROX_ALPHA,
                protected_var_names=art.protected_var_names,
                backbone_lr_mult=BACKBONE_LR_MULT,
            )
            wrapper.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

            t_stage2 = 0.0  # already counted in trials; to keep time honest, you can remove tuning or measure differently
            t_adapt = t_stage1 + t_stage2

            # Target TEST
            _, _, met_med_test = eval_domain(wrapper, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
            pretty_print_metrics(f"Medical TEST (DAEWC, best_lambda={best_lambda})", met_med_test)

            # Source TEST after
            pol_test_prob_after = wrapper.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
            met_src_after = evaluate_with_threshold(y_pol_test, pol_test_prob_after, art.thr_pol)
            pretty_print_metrics("Political TEST after (DAEWC)", met_src_after)

            add_record(
                seed=seed,
                shot=k,
                method="DAEWC",
                met_tgt_test=met_med_test,
                met_src_test_after=met_src_after,
                src_f1_pre=src_f1_pre_plain,
                src_thr_pre=art.thr_pol,
                trainable_params=count_trainable_params(dae),
                t_pretrain=art.time_pre,
                t_fisher=art.time_fisher,
                t_adapt=t_adapt,
            )

        # =========================================================
        # Replay upper bound (joint training)
        # =========================================================
        if INCLUDE_REPLAY_UPPER:
            print("\n[Replay Upper (Joint training)]")
            clear_tf()
            reset_seeds(seed)

            joint = build_plain_cnn_mh(VOCAB_SIZE)

            X_joint = np.concatenate([X_pol_train, X_med_sub], axis=0)
            y_joint = np.concatenate([y_pol_train, y_med_sub], axis=0)
            D_joint = np.concatenate([D_pol_train, D_med_sub], axis=0)

            for layer in joint.layers:
                layer.trainable = True
            joint.compile(optimizer=make_optimizer(LR_TARGET), loss="binary_crossentropy")

            t_adapt = timed_fit(
                joint,
                {"tokens": X_joint, "domain_id": D_joint}, y_joint,
                {"tokens": X_med_dev, "domain_id": D_med_dev}, y_med_dev,
                epochs=EPOCHS_TARGET_STAGE1,
                batch_size=BATCH_SIZE_SOURCE,
                verbose=0,
            )

            _, _, met_med_test = eval_domain(joint, X_med_dev, y_med_dev, D_med_dev, X_med_test, y_med_test, D_med_test)
            pretty_print_metrics("Medical TEST (ReplayUpper)", met_med_test)

            pol_test_prob_after = joint.predict({"tokens": X_pol_test, "domain_id": D_pol_test}, verbose=0).ravel()
            met_src_after = evaluate_with_threshold(y_pol_test, pol_test_prob_after, art.thr_pol)
            pretty_print_metrics("Political TEST (ReplayUpper)", met_src_after)

            add_record(
                seed=seed,
                shot=k,
                method="ReplayUpper",
                met_tgt_test=met_med_test,
                met_src_test_after=met_src_after,
                src_f1_pre=src_f1_pre_plain,
                src_thr_pre=art.thr_pol,
                trainable_params=count_trainable_params(joint),
                t_pretrain=0.0,
                t_fisher=0.0,
                t_adapt=t_adapt,
            )

# Save + summarize
df = pd.DataFrame(records)
summarize_and_save(df)
print("\nDone.")
